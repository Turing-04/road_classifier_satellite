Please append to this file the current accuracy you have for a given model (Unet, CNN, Xception... ? ) with the number of epochs / hyperparams
And especially the loss at after each epoch -> To be recorded here after each training period

Essential for the report to come !


30 epochs, U-net -> 0.895 F1 score 0.933, training dataset with 1000 samples (from sratch weights)


60 epochs, U-net -> 0.895 F1 score 0.945, training dataset with 1100 samples (antoine, only rotations / flipping but with repeting dataset) (from scratch weights)


80 epochs, Basic U-net -> 0.875, F1 score:0.934, Marin's data augmentation (900 samples):
losses=[0.8216245493623946, 0.5422054453028573, 0.45624896215067967, 0.39450105809503133, 0.3740843512614568, 0.33934757073720295, 0.31171434415711297, 0.29711321079068714, 0.28080149047904546, 0.26728939218653575, 0.26565327213870155, 0.2517532204588254, 0.2347977066040039, 0.2290028390950627, 0.21724024484554927, 0.23011629068189196, 0.2221700151099099, 0.2031264789071348, 0.1955354364381896, 0.18760695492227872, 0.21182107168767186, 0.1983269962337282, 0.17863923407263227, 0.1731806512673696, 0.17028251164489322, 0.1862174954182572, 0.17434434306290414, 0.16803391239709325, 0.17140161726209852, 0.1621779717836115, 0.15935334119531844, 0.16157615663276778, 0.18765870604250165, 0.1557986015578111, 0.1586538788676262, 0.15253067567944525, 0.16426936250593926, 0.17222825088434748, 0.15194130311409632, 0.14814110787378418, 0.1534139349228806, 0.15346083755294482, 0.15274518079227872, 0.14909644103712505, 0.1469741752743721, 0.148070676939355, 0.16489513190256225, 0.1486604721016354, 0.14407496187422011, 0.14418292934695878, 0.14439637523558405, 0.17220824946959815, 0.14562142946653897, 0.1422411410841677, 0.14169667661190033, 0.16542590166131654, 0.14384175742665928, 0.14193710757626427, 0.14081118105186358, 0.1414958649377028, 0.14115476056933404, 0.14301788061857224, 0.14264949204193222, 0.14213492467999458, 0.1540983316467868, 0.1432336950302124, 0.13879902644289865, 0.13845295078224606, 0.13918791299064953, 0.14067982910407914, 0.1399626374575827, 0.13998906296160485, 0.1409540914495786, 0.14431852747996649, 0.14450248209966554, 0.1390339373714394, 0.15481124737196497, 0.138491816404793, 0.13514803055259916, 0.13461955037381915]

same but only 40 epoch - 0.885, F1=0.940: 
losses = [0.8216245493623946, 0.5422054453028573, 0.45624896215067967, 0.39450105809503133, 0.3740843512614568, 0.33934757073720295, 0.31171434415711297, 0.29711321079068714, 0.28080149047904546, 0.26728939218653575, 0.26565327213870155, 0.2517532204588254, 0.2347977066040039, 0.2290028390950627, 0.21724024484554927, 0.23011629068189196, 0.2221700151099099, 0.2031264789071348, 0.1955354364381896, 0.18760695492227872, 0.21182107168767186, 0.1983269962337282, 0.17863923407263227, 0.1731806512673696, 0.17028251164489322, 0.1862174954182572, 0.17434434306290414, 0.16803391239709325, 0.17140161726209852, 0.1621779717836115, 0.15935334119531844, 0.16157615663276778, 0.18765870604250165, 0.1557986015578111, 0.1586538788676262, 0.15253067567944525, 0.16426936250593926, 0.17222825088434748, 0.15194130311409632, 0.14814110787378418]

same with 55 epoch - acc=0.889 F1=0.941:
losses=[0.8216245493623946, 0.5422054453028573, 0.45624896215067967, 0.39450105809503133, 0.3740843512614568, 0.33934757073720295, 0.31171434415711297, 0.29711321079068714, 0.28080149047904546, 0.26728939218653575, 0.26565327213870155, 0.2517532204588254, 0.2347977066040039, 0.2290028390950627, 0.21724024484554927, 0.23011629068189196, 0.2221700151099099, 0.2031264789071348, 0.1955354364381896, 0.18760695492227872, 0.21182107168767186, 0.1983269962337282, 0.17863923407263227, 0.1731806512673696, 0.17028251164489322, 0.1862174954182572, 0.17434434306290414, 0.16803391239709325, 0.17140161726209852, 0.1621779717836115, 0.15935334119531844, 0.16157615663276778, 0.18765870604250165, 0.1557986015578111, 0.1586538788676262, 0.15253067567944525, 0.16426936250593926, 0.17222825088434748, 0.15194130311409632, 0.14814110787378418, 0.1534139349228806, 0.15346083755294482, 0.15274518079227872, 0.14909644103712505, 0.1469741752743721, 0.148070676939355, 0.16489513190256225, 0.1486604721016354, 0.14407496187422011, 0.14418292934695878, 0.14439637523558405, 0.17220824946959815, 0.14562142946653897, 0.1422411410841677, 0.14169667661190033]

50 epochs, cnn16, F1:0.560,	acc:0.781
[1.4612571475240919, 1.3821242952346802, 1.3276965747939216, 1.278738153245714, 1.2363285130924648, 1.2042076455222235, 1.1807094981935289, 1.1563590003384485, 1.1370153286721971, 1.1222055651081932, 1.1078563059700859, 1.0966064258416495, 1.088292614751392, 1.0806414274374645, 1.0752597469753689, 1.0678815428415935, 1.0633759187327492, 1.0595504997836218, 1.058351985613505, 1.0532632244957818, 1.0512659102016024, 1.0518066730764177, 1.0493853500154284, 1.0458776108423868, 1.0410099233521355, 1.0451514707671272, 1.0445100017388662, 1.0404670935206943, 1.0436071097850799, 1.0361200388272602, 1.0333451669745974, 1.0404689719941882, 1.0316878305541144, 1.0356717885865105, 1.0329800502459208, 1.031337748368581, 1.0324597701761458, 1.0280844516224332, 1.0336266794469622, 1.0294600987434388, 1.029387230740653, 1.0293171841568416, 1.0296000085936652, 1.0273783842722575, 1.0276922982268863, 1.024765402475993, 1.0228810180558099, 1.025966581636005, 1.0279537264506022, 1.0236940484576755]

50 epochs, cnn4, F1:0.591,	acc:0.803
[1.3029563607109917, 1.2517039288414848, 1.21849035554462, 1.194526960849762, 1.1709564418262906, 1.1538910694917044, 1.1273357105255126, 1.0946927369965447, 1.0747257607513003, 1.0631217186980777, 1.050767591661877, 1.046948635313246, 1.0409223857190875, 1.036800389819675, 1.0363096311357287, 1.030641153521008, 1.0288906863000657, 1.0258088764879438, 1.0260296408335368, 1.0237021402517954, 1.025619367758433, 1.0226485231187608, 1.0194274469216664, 1.0191140210628509, 1.0204369299941594, 1.0178564993540447, 1.0141026037269167, 1.0153743267059325, 1.0119534611701966, 1.0116905433601804, 1.0088933424154918, 1.0094050199455684, 1.0118589198589325, 1.0069289984967973, 1.0142938519848717, 1.00818874835968, 1.0100191685888502, 1.0124075763755374, 1.0090126225683425, 1.006687547100915, 1.0103006439738804, 1.0066130636798012, 1.0065248771508535, 1.0061466281943852, 1.004367254310184, 1.005252998669942, 1.005622718334198, 1.0039466410213047, 1.0063876582516564, 1.0049560157457988]


50 epochs, cnn2, F1:0.624, acc: 0.816
[1.3286846963564556, 1.2736767212549844, 1.235722230805291, 1.1835708226097954, 1.1399078626102872, 1.1071506477726831, 1.0845456087589265, 1.065623428026835, 1.0521723373730978, 1.0383191647794512, 1.027482761674457, 1.0186108214325376, 1.0151081828276316, 1.0119796416494582, 1.0098648635546366, 1.0043046613534292, 0.9981239528126187, 0.9975627969370948, 0.9968840078512827, 1.0001859533786774, 0.9960802866352929, 0.9905095389154223, 0.9883073867691887, 0.9873217199908363, 0.9905941424104903, 0.9918426118956671, 0.9863332410653433, 0.9891126884354485, 0.9840185358789232, 0.9874448613325755, 0.9820541761981116, 0.979367305305269, 0.9818004773722755, 0.9790896509753333, 0.9770476207468245, 0.9811107301712036, 0.970694936381446, 0.9775416535801358, 0.9745123304261102, 0.9735032074981266, 0.9769770831531949, 0.9722391449080573, 0.97421428071128, 0.9733849537372589, 0.9711684362093608, 0.9721378178066677, 0.9711245475875007, 0.9677990047136943, 0.9733020830154419, 0.9712233134110768]

50 epochs, cnn8, F1: 0.554, acc: 0.800
[1.5586756091647678, 1.4605056929588318, 1.4021497941017151, 1.3518880359331766, 1.3100710344314574, 1.2745235747761197, 1.2417953130933974, 1.2126108479499818, 1.1859637170367772, 1.1622294678952958, 1.141787407928043, 1.1223552689287397, 1.1065204768710666, 1.0953971486621432, 1.081367579433653, 1.0664101282755534, 1.0624842802683512, 1.0508561046918232, 1.0461829348405203, 1.042060103946262, 1.0409312799241808, 1.0311749249034459, 1.0283355422814686, 1.0296556454234653, 1.035030593474706, 1.0285386796792348, 1.0279461379845938, 1.0237841737270355, 1.0231368466218314, 1.0220510600672827, 1.022900956471761, 1.0219719984796312, 1.0192062275939517, 1.0188792272408804, 1.0162661618656583, 1.01520563032892, 1.0182915759086608, 1.0139401557710435, 1.0150955737961662, 1.0159433420499167, 1.0154965586132474, 1.0165765990151299, 1.0153937281502619, 1.0114351190461053, 1.0122538846068911, 1.0124932984511057, 1.0065509924623701, 1.0092794570657941, 1.00691515300009, 1.0052200384934744]